{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_reconstruction_error.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5993468b8a2043549b62e230f2a4e8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12edf0ef1e2c4a39b44b2cc64d6aa8ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cfa9bf021f5848a194113d955572721b",
              "IPY_MODEL_576fe83ba36845ce989b00d5809f9b1a"
            ]
          }
        },
        "12edf0ef1e2c4a39b44b2cc64d6aa8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfa9bf021f5848a194113d955572721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b32a0d5205eb4582bb776e659365d755",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 561753746,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 561753746,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5ee826458784b2982bbc20d614d2298"
          }
        },
        "576fe83ba36845ce989b00d5809f9b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_185bbbce6cde4f539957adaf28770030",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 561754112/? [01:01&lt;00:00, 9146929.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d6a0b0d372040c9ba48c5cfcd2d1a5a"
          }
        },
        "b32a0d5205eb4582bb776e659365d755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5ee826458784b2982bbc20d614d2298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "185bbbce6cde4f539957adaf28770030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d6a0b0d372040c9ba48c5cfcd2d1a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwUzY0w4acCw",
        "outputId": "6c5f1c1a-90d0-4970-893a-c1c92dc7a612"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules import loss\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import csc413_final_project_code\n",
        "from csc413_final_project_code import DCGenerator\n",
        "from urllib.error import URLError\n",
        "from urllib.error import HTTPError\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def log_to_tensorboard(iteration, losses):\n",
        "    writer = SummaryWriter(\"/content/runs/\")\n",
        "    for key in losses:\n",
        "        arr = losses[key]\n",
        "        writer.add_scalar(f'loss/{key}', arr[-1], iteration)\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "\n",
        "def to_var(tensor, cuda=True):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/emojis.tar.gz\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/emojis.tar.gz\n",
            "Extracting file.\n",
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                             image_size: 32                                     \n",
            "                             g_conv_dim: 32                                     \n",
            "                             d_conv_dim: 64                                     \n",
            "                             noise_size: 100                                    \n",
            "                            train_iters: 100000                                 \n",
            "                                      X: letters                                \n",
            "                                     lr: 0.0005                                 \n",
            "                                  beta1: 0.5                                    \n",
            "                                  beta2: 0.999                                  \n",
            "                             batch_size: 64                                     \n",
            "                         checkpoint_dir: results/checkpoints_gan_final          \n",
            "                             sample_dir: results/samples_gan_final              \n",
            "                               log_step: 200                                    \n",
            "                           sample_every: 1000                                   \n",
            "                       checkpoint_every: 1000                                   \n",
            "                          d_train_iters: 1                                      \n",
            "                          g_train_iters: 1                                      \n",
            "                      train_data_subset: full                                   \n",
            "                       adversarial_loss: BCEWithLogitsLoss                      \n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrFiT5ofahLS"
      },
      "source": [
        "def get_zero_vector(dim):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    return torch.zeros(1, dim).requires_grad_()\n",
        "\n",
        "\n",
        "def get_emnist_loader(opts):\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(opts.image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5), (0.5)),\n",
        "                ])\n",
        "    train = datasets.EMNIST(\".\", split=opts.X,train = True, download = True, transform= transform)\n",
        "    test = datasets.EMNIST(\".\", split=opts.X,train = False, download = True, transform = transform)\n",
        "    \n",
        "    train_dloader = DataLoader(dataset=train, batch_size=opts.batch_size, shuffle=True,num_workers=opts.num_workers, drop_last=True)\n",
        "    \n",
        "    test_dloader = DataLoader(dataset=test, batch_size=opts.batch_size, shuffle=False,num_workers=opts.num_workers)\n",
        "    # return train_dloader, test_dloader\n",
        "    return test_dloader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JyG8esLaGD9"
      },
      "source": [
        "def load_generator(opts) -> nn.Module:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.load, opts.G_name)\n",
        "    print(G_path)\n",
        "    G = DCGenerator(noise_size=opts.noise_size,\n",
        "                    conv_dim=opts.g_conv_dim, spectral_norm=False)\n",
        "\n",
        "    G.load_state_dict(torch.load(\n",
        "        G_path, map_location=lambda storage, loc: storage))\n",
        "    return G\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    G = load_generator(opts)\n",
        "    z = get_zero_vector(opts.noise_size)\n",
        "\n",
        "    z_optimizer = optim.SGD([z], lr=1e-4)\n",
        "    test_data = get_emnist_loader(opts)\n",
        "    train_iter = iter(test_data)\n",
        "    iter_per_epoch = len(train_iter)\n",
        "\n",
        "    criteria = nn.MSELoss()\n",
        "    iteration = 0\n",
        "    epoch = 0\n",
        "    losses = {\"reconstruction_loss\": []}\n",
        "    for i in range(opts.iterations):\n",
        "        sample, target = train_iter.next()\n",
        "        if iteration % iter_per_epoch == 0:\n",
        "            epoch += 1\n",
        "            train_iter = iter(test_data)\n",
        "            print(\"epoch:\", epoch)\n",
        "\n",
        "        z_optimizer.zero_grad()\n",
        "        Loss = criteria(G(z.unsqueeze(2).unsqueeze(3)), sample)\n",
        "        Loss.backward()\n",
        "        z_optimizer.step()\n",
        "        if iteration % opts.log_step == 0:\n",
        "            losses[\"reconstruction_loss\"].append(Loss.item())\n",
        "            log_to_tensorboard(iteration, losses)\n",
        "            print('iteration: ', iteration, \"loss: \", Loss.item())\n",
        "            \n",
        "            df = pd.DataFrame(losses) \n",
        "            df.to_csv('reconstruction_losses.csv') \n",
        "\n",
        "        iteration += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5993468b8a2043549b62e230f2a4e8fa",
            "12edf0ef1e2c4a39b44b2cc64d6aa8ed",
            "cfa9bf021f5848a194113d955572721b",
            "576fe83ba36845ce989b00d5809f9b1a",
            "b32a0d5205eb4582bb776e659365d755",
            "e5ee826458784b2982bbc20d614d2298",
            "185bbbce6cde4f539957adaf28770030",
            "2d6a0b0d372040c9ba48c5cfcd2d1a5a"
          ]
        },
        "id": "wacPGlc1aP6P",
        "outputId": "64b8e70b-16d3-46bd-c807-4d261f5f4d5d"
      },
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "        'image_size': 32,\n",
        "        'g_conv_dim': 32,\n",
        "        'noise_size': 100,\n",
        "        'num_workers': 0,\n",
        "        'iterations': 120000,\n",
        "        'X': 'letters',\n",
        "        'batch_size': 16,\n",
        "        'load': \"/content/pretrained_models/\",\n",
        "        'log_step': 1000,\n",
        "        'sample_every': 200,\n",
        "        'checkpoint_every': 1000,\n",
        "        'G_name': 'G-100.pkl'\n",
        "    }\n",
        "args.update(args_dict)\n",
        "train(args)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pretrained_models/G-100.pkl\n",
            "Downloading and extracting zip archive\n",
            "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5993468b8a2043549b62e230f2a4e8fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=561753746.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./EMNIST/raw/emnist.zip to ./EMNIST/raw\n",
            "Processing byclass\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n",
            "epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([16, 1, 32, 32])) that is different to the input size (torch.Size([1, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration:  0 loss:  0.6260254383087158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([16, 1, 32, 32])) that is different to the input size (torch.Size([1, 1, 32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration:  1000 loss:  0.3870023787021637\n",
            "epoch: 2\n",
            "iteration:  2000 loss:  0.6174291372299194\n",
            "epoch: 3\n",
            "iteration:  3000 loss:  0.46050530672073364\n",
            "epoch: 4\n",
            "iteration:  4000 loss:  0.5706568956375122\n",
            "iteration:  5000 loss:  0.5679577589035034\n",
            "epoch: 5\n",
            "iteration:  6000 loss:  0.47721099853515625\n",
            "epoch: 6\n",
            "iteration:  7000 loss:  0.5574061870574951\n",
            "epoch: 7\n",
            "iteration:  8000 loss:  0.5497928857803345\n",
            "iteration:  9000 loss:  0.37520188093185425\n",
            "epoch: 8\n",
            "iteration:  10000 loss:  0.5386103391647339\n",
            "epoch: 9\n",
            "iteration:  11000 loss:  0.36219146847724915\n",
            "epoch: 10\n",
            "iteration:  12000 loss:  0.42995479702949524\n",
            "epoch: 11\n",
            "iteration:  13000 loss:  0.5012283325195312\n",
            "iteration:  14000 loss:  0.38744527101516724\n",
            "epoch: 12\n",
            "iteration:  15000 loss:  0.6068238615989685\n",
            "epoch: 13\n",
            "iteration:  16000 loss:  0.46048253774642944\n",
            "epoch: 14\n",
            "iteration:  17000 loss:  0.5723498463630676\n",
            "iteration:  18000 loss:  0.5656113624572754\n",
            "epoch: 15\n",
            "iteration:  19000 loss:  0.47531357407569885\n",
            "epoch: 16\n",
            "iteration:  20000 loss:  0.5683420300483704\n",
            "epoch: 17\n",
            "iteration:  21000 loss:  0.5552305579185486\n",
            "iteration:  22000 loss:  0.3748381733894348\n",
            "epoch: 18\n",
            "iteration:  23000 loss:  0.5303630232810974\n",
            "epoch: 19\n",
            "iteration:  24000 loss:  0.37173354625701904\n",
            "epoch: 20\n",
            "iteration:  25000 loss:  0.4306972920894623\n",
            "epoch: 21\n",
            "iteration:  26000 loss:  0.5044453144073486\n",
            "iteration:  27000 loss:  0.3887619972229004\n",
            "epoch: 22\n",
            "iteration:  28000 loss:  0.5986359715461731\n",
            "epoch: 23\n",
            "iteration:  29000 loss:  0.4604521095752716\n",
            "epoch: 24\n",
            "iteration:  30000 loss:  0.5721758604049683\n",
            "iteration:  31000 loss:  0.5655248761177063\n",
            "epoch: 25\n",
            "iteration:  32000 loss:  0.4753400683403015\n",
            "epoch: 26\n",
            "iteration:  33000 loss:  0.5683885812759399\n",
            "epoch: 27\n",
            "iteration:  34000 loss:  0.5552319288253784\n",
            "iteration:  35000 loss:  0.3748137950897217\n",
            "epoch: 28\n",
            "iteration:  36000 loss:  0.5303470492362976\n",
            "epoch: 29\n",
            "iteration:  37000 loss:  0.37170523405075073\n",
            "epoch: 30\n",
            "iteration:  38000 loss:  0.4306817650794983\n",
            "epoch: 31\n",
            "iteration:  39000 loss:  0.504410982131958\n",
            "iteration:  40000 loss:  0.3887389004230499\n",
            "epoch: 32\n",
            "iteration:  41000 loss:  0.5986565947532654\n",
            "epoch: 33\n",
            "iteration:  42000 loss:  0.4604284167289734\n",
            "epoch: 34\n",
            "iteration:  43000 loss:  0.5721598267555237\n",
            "iteration:  44000 loss:  0.5654950141906738\n",
            "epoch: 35\n",
            "iteration:  45000 loss:  0.4753287434577942\n",
            "epoch: 36\n",
            "iteration:  46000 loss:  0.5683203935623169\n",
            "epoch: 37\n",
            "iteration:  47000 loss:  0.555187463760376\n",
            "iteration:  48000 loss:  0.3747894763946533\n",
            "epoch: 38\n",
            "iteration:  49000 loss:  0.5303629636764526\n",
            "epoch: 39\n",
            "iteration:  50000 loss:  0.3716326057910919\n",
            "epoch: 40\n",
            "iteration:  51000 loss:  0.43065959215164185\n",
            "epoch: 41\n",
            "iteration:  52000 loss:  0.5043695569038391\n",
            "iteration:  53000 loss:  0.3887077867984772\n",
            "epoch: 42\n",
            "iteration:  54000 loss:  0.5987138152122498\n",
            "epoch: 43\n",
            "iteration:  55000 loss:  0.46040448546409607\n",
            "epoch: 44\n",
            "iteration:  56000 loss:  0.5721442103385925\n",
            "iteration:  57000 loss:  0.5654663443565369\n",
            "epoch: 45\n",
            "iteration:  58000 loss:  0.47531652450561523\n",
            "epoch: 46\n",
            "iteration:  59000 loss:  0.5682464241981506\n",
            "epoch: 47\n",
            "iteration:  60000 loss:  0.5551444292068481\n",
            "iteration:  61000 loss:  0.374765008687973\n",
            "epoch: 48\n",
            "iteration:  62000 loss:  0.5303685665130615\n",
            "epoch: 49\n",
            "iteration:  63000 loss:  0.37158724665641785\n",
            "epoch: 50\n",
            "iteration:  64000 loss:  0.4306415021419525\n",
            "epoch: 51\n",
            "iteration:  65000 loss:  0.5043336153030396\n",
            "iteration:  66000 loss:  0.3886823356151581\n",
            "epoch: 52\n",
            "iteration:  67000 loss:  0.5987492799758911\n",
            "epoch: 53\n",
            "iteration:  68000 loss:  0.46038052439689636\n",
            "epoch: 54\n",
            "iteration:  69000 loss:  0.572130560874939\n",
            "iteration:  70000 loss:  0.5654374957084656\n",
            "epoch: 55\n",
            "iteration:  71000 loss:  0.47530391812324524\n",
            "epoch: 56\n",
            "iteration:  72000 loss:  0.5681647062301636\n",
            "epoch: 57\n",
            "iteration:  73000 loss:  0.555083692073822\n",
            "iteration:  74000 loss:  0.3747406601905823\n",
            "epoch: 58\n",
            "iteration:  75000 loss:  0.5303840041160583\n",
            "epoch: 59\n",
            "iteration:  76000 loss:  0.3715207576751709\n",
            "epoch: 60\n",
            "iteration:  77000 loss:  0.4306124448776245\n",
            "epoch: 61\n",
            "iteration:  78000 loss:  0.5042855143547058\n",
            "iteration:  79000 loss:  0.3886544406414032\n",
            "epoch: 62\n",
            "iteration:  80000 loss:  0.5987911224365234\n",
            "epoch: 63\n",
            "iteration:  81000 loss:  0.460356742143631\n",
            "epoch: 64\n",
            "iteration:  82000 loss:  0.5721147060394287\n",
            "iteration:  83000 loss:  0.5654079914093018\n",
            "epoch: 65\n",
            "iteration:  84000 loss:  0.47529223561286926\n",
            "epoch: 66\n",
            "iteration:  85000 loss:  0.5680899024009705\n",
            "epoch: 67\n",
            "iteration:  86000 loss:  0.5550305247306824\n",
            "iteration:  87000 loss:  0.37471604347229004\n",
            "epoch: 68\n",
            "iteration:  88000 loss:  0.5303940773010254\n",
            "epoch: 69\n",
            "iteration:  89000 loss:  0.3714630901813507\n",
            "epoch: 70\n",
            "iteration:  90000 loss:  0.4305835962295532\n",
            "epoch: 71\n",
            "iteration:  91000 loss:  0.5042445063591003\n",
            "iteration:  92000 loss:  0.3886275887489319\n",
            "epoch: 72\n",
            "iteration:  93000 loss:  0.5988341569900513\n",
            "epoch: 73\n",
            "iteration:  94000 loss:  0.46033287048339844\n",
            "epoch: 74\n",
            "iteration:  95000 loss:  0.5720990300178528\n",
            "iteration:  96000 loss:  0.5653775334358215\n",
            "epoch: 75\n",
            "iteration:  97000 loss:  0.4752824008464813\n",
            "epoch: 76\n",
            "iteration:  98000 loss:  0.5680279731750488\n",
            "epoch: 77\n",
            "iteration:  99000 loss:  0.5549795627593994\n",
            "iteration:  100000 loss:  0.37469154596328735\n",
            "epoch: 78\n",
            "iteration:  101000 loss:  0.5303996801376343\n",
            "epoch: 79\n",
            "iteration:  102000 loss:  0.37140920758247375\n",
            "epoch: 80\n",
            "iteration:  103000 loss:  0.43055716156959534\n",
            "epoch: 81\n",
            "iteration:  104000 loss:  0.5042039752006531\n",
            "iteration:  105000 loss:  0.3886030614376068\n",
            "epoch: 82\n",
            "iteration:  106000 loss:  0.5988616943359375\n",
            "epoch: 83\n",
            "iteration:  107000 loss:  0.46030887961387634\n",
            "epoch: 84\n",
            "iteration:  108000 loss:  0.5720844268798828\n",
            "iteration:  109000 loss:  0.5653491020202637\n",
            "epoch: 85\n",
            "iteration:  110000 loss:  0.4752705693244934\n",
            "epoch: 86\n",
            "iteration:  111000 loss:  0.567948579788208\n",
            "epoch: 87\n",
            "iteration:  112000 loss:  0.5549147129058838\n",
            "iteration:  113000 loss:  0.3746669292449951\n",
            "epoch: 88\n",
            "iteration:  114000 loss:  0.5304166674613953\n",
            "epoch: 89\n",
            "iteration:  115000 loss:  0.3713388741016388\n",
            "epoch: 90\n",
            "iteration:  116000 loss:  0.43051937222480774\n",
            "epoch: 91\n",
            "iteration:  117000 loss:  0.504152238368988\n",
            "iteration:  118000 loss:  0.3885701596736908\n",
            "epoch: 92\n",
            "iteration:  119000 loss:  0.598951518535614\n",
            "epoch: 93\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}